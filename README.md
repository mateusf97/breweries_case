# ğŸ“˜ DocumentaÃ§Ã£o TÃ©cnica - Projeto Breweries Case

## ğŸš€ Como Iniciar o Projeto
1. Clone o repositÃ³rio:
```
git clone git@github.com:mateusf97/breweries_case.git
cd breweries_case
```

2. DÃª permissÃ£o de leitura e escrita para as pastas essenciais:
```
chmod -R 777 ./logs ./data ./dags
```

3. Suba o projeto com Docker Compose (no Linux):
```
docker compose up --build
```

4. Acesse a pÃ¡gina web em:
```
http://localhost:8088/
```

**Login padrÃ£o:**
```
UsuÃ¡rio: Admin
Senha: admin
```

## ğŸ“‚ Arquitetura do Pipeline
### 1ï¸âƒ£ Bronze Layer
- Coleta os dados da API Open Brewery com paginaÃ§Ã£o.
- Armazena os dados brutos em JSON.
- Se falhar, tenta novamente ao final.

Trecho de cÃ³digo:
```python
for url in failed_urls:
    try:
        response = requests.get(url)
        response.raise_for_status()
        data = response.json()
        all_data.extend(data)
        logging.info(f"ğŸ” Retry bem-sucedido para: {url}")
    except Exception as e:
        logging.error(f"âŒ Falha permanente em: {url}")
```

### 2ï¸âƒ£ Silver Layer
- Converte o JSON em Parquet.
- Particiona por estado.
- Tipagem e limpeza de dados.

### 3ï¸âƒ£ Gold Layer
- Agrega os dados da Silver.
- Gera 3 arquivos CSV:
  - brewery_count_by_type.csv
  - brewery_count_by_state.csv
  - brewery_count_by_type_and_state.csv

## ğŸ“Š PÃ¡gina Web
Fiz o processamento dos arquivos da GOLD, e gerei um mapa HTML+JS para visualizar as informaÃ§Ãµes, basta acessar o arquivo .html

**Acesso:**

```
html_view/brewery_dashboard_final_mateus.html
```

## ğŸ“¬ Sistema de Monitoramento
Airflow gera logs e envia e-mails de falha.

Exemplo de log:
```bash
âŒ Erro ao ler arquivo: /opt/airflow/data/silver/breweries/state=XX/breweries.parquet
```

## ğŸ§  Tecnologias Utilizadas
- Airflow
- Python
- PySpark
- Parquet
- Docker
- Git

## ğŸ“ˆ Camadas Adicionais no GOLD
AlÃ©m das agregaÃ§Ãµes principais, temos tambÃ©m:
- brewery_count_by_type.csv
- brewery_count_by_state.csv
- brewery_count_by_type_and_state.csv

## ğŸ—‚ Estrutura de DiretÃ³rios

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ bronze/
â”‚   â”œâ”€â”€ silver/
â”‚   â””â”€â”€ gold/
â”œâ”€â”€ dags/
â”œâ”€â”€ html_view/
â””â”€â”€ docker-compose.yml
```


# âœ… Testes Automatizados - Brewery Pipeline

Este projeto inclui uma suÃ­te de testes para validar o funcionamento do pipeline de dados que extrai, transforma e agrega informaÃ§Ãµes da Open Brewery API.

## ğŸ”§ PrÃ©-requisitos

- Projeto jÃ¡ rodando com Docker e Airflow.
- A DAG `brewery_pipeline_bronze_silver_gold` deve ter sido executada pelo menos uma vez.

## ğŸš€ Executando os Testes

### 1. Acesse o container do Airflow:

```bash
docker exec -it airflow_scheduler bash
```

### 2. Execute os testes com Pytest:

```bash
pytest dags/test/test_pipeline.py --disable-warnings
```

## ğŸ§ª O que estÃ¡ sendo testado?

| Teste                           | Objetivo                                               |
|-------------------------------|--------------------------------------------------------|
| `test_api_status_code_200`     | Verifica se a API responde com status 200             |
| `test_api_content`             | Valida o conteÃºdo da resposta da API                  |
| `test_extract_creates_bronze`  | Verifica a criaÃ§Ã£o correta do arquivo bronze JSON     |
| `test_transform_creates_silver`| Verifica a transformaÃ§Ã£o para Parquet na camada Silver|
| `test_aggregate_creates_gold`  | Confirma a geraÃ§Ã£o dos arquivos CSV agregados         |

Todos os arquivos de output sÃ£o esperados em `/opt/airflow/data`.


